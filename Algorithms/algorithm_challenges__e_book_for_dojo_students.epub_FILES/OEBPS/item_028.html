<?xml version="1.0" encoding="utf-8" standalone="no"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="application/xhtml+xml; charset=utf-8" /><meta http-equiv="Content-Style-Type" content="text/css" /><meta name="description" content="Computer Science Algorithms Data Structures JavaScript JS" /><meta name="generator" content="Aspose.Words for .NET 13.6.0.0" /><title>Algorithms_Collection</title><link href="item_083.css" type="text/css" rel="stylesheet" /></head><body><div style="clear:both; mso-break-type:section-break; page-break-before:auto"><h2 id="navPoint_85"><span>Big-O Notation</span></h2><p class="Normal1"><span>Previously</span><span> we mentioned that when analyzing algorithms, comparisons must be relative, when given different inputs. Specifically, as we increase the </span><span>input </span><span>size by 10, how does the time needed to run the algorithm change?</span><span> </span><span>How does memory consumption change?</span><span> </span><span>Generally, there are only a few growth rate</span><span> type</span><span>s</span><span>. T</span><span>he mathematical convention </span><span>that</span><span> represent</span><span>s</span><span> these growth factors is called </span><span style="text-decoration:underline">Big-O notation</span><span>. </span></p><p class="Normal1"><span>&#xa0;</span></p><p class="Normal1"><span>S</span><span>ide note: really hard-core algorithm analysis experts talk not only about Big-O but also </span><span style="font-style:italic">Big-Omega</span><span> and </span><span style="font-style:italic">Big-Theta</span><span>. In brief, Big-O describes </span><span style="font-style:italic">worse-case</span><span> performance</span><span> (“performance will never be any worse than …”)</span><span>; Big-Omega </span><span style="font-style:italic">best-case</span><span> (“in the ideal situation, performance might be as good as …”)</span><span>; </span><span>Big-Theta </span><span style="font-style:italic">average case</span><span> (“on average across a broad range of inputs, performance will be …”).</span><span> Their values </span><span>can differ</span><span>, but </span><span>for</span><span> </span><span>many analyses </span><span>you </span><span>can</span><span> think of them as the same. Further, when best-case and worst-case differ, most people talk </span><span>mostly </span><span>about Big-O</span><span> and </span><span>secondarily</span><span> mention “best-case”. </span></p><p class="Normal1"><span>&#xa0;</span></p><p class="Normal1"><span>What does Big-O notation indicate? It conveys how </span><span>an</span><span> algorithm will perform, as input sizes grow large. </span><span>As we multiply our input </span><span>by factor N, </span><span>how</span><span> </span><span>do our </span><span>run time </span><span>and </span><span>memory consumption change? In </span><span>practice</span><span>, we would first </span><span>measure the time and memory consumed when running with </span><span>an input of specific </span><span style="font-style:italic">size</span><span>; then </span><span>measure the same when given </span><span>a</span><span>n input of “size x N” – this </span><span>ratio, in terms of N, is our Big-O. </span></p><p class="Normal1"><span>&#xa0;</span></p><p class="Normal1" style="line-height:115%"><span>Consider</span><span> </span><span class="CodeSnippet" style="font-family:Times, serif">FindMax()</span><span> </span><span>that </span><span>return</span><span>s</span><span> </span><span>an array’s </span><span>lowest value. If we double array </span><span>length</span><span>, we expect </span><span class="CodeSnippet" style="font-family:Times, serif">FindMax</span><span> </span><span>to run twice as long. </span><span>I</span><span>f we multiply arr</span><span>ay length by N, run time should multiply </span><span>by exactly N as well. Hence we say the time complexity of this algorithm is </span><span class="CodeSnippet" style="font-family:Times, serif">O(</span><span class="CodeSnippet" style="font-family:Times, serif">N</span><span class="CodeSnippet" style="font-family:Times, serif">)</span><span>, or verbally </span><span>“</span><span>f</span><span>or run-time, it has a Big-O of N</span><span>.</span><span>”</span><span> Looking at memory consumption, the only memory needed is local storage of a </span><span class="CodeSnippet" style="font-family:Times, serif">FOR</span><span> loop index, and a local variable to track the min value. This is the case </span><span style="font-style:italic">regardless</span><span> of the array</span><span>’</span><span>s length, so as we multiply array length by N, our additional memory requirements are constant (i.e., multiplied by </span><span style="font-weight:bold; text-decoration:underline">1</span><span>). Hence the </span><span>algorithm’s </span><span>memory complexity is </span><span class="CodeSnippet" style="font-family:Times, serif">O(</span><span class="CodeSnippet" style="font-family:Times, serif">1</span><span class="CodeSnippet" style="font-family:Times, serif">)</span><span>, or verbally </span><span>“</span><span>for memory, Big-O is 1.</span><span>”</span><span> If our algorithm needed to make a copy of the array, then the Big-O for memory would be </span><span class="CodeSnippet" style="font-family:Times, serif">O(</span><span class="CodeSnippet" style="font-family:Times, serif">N</span><span class="CodeSnippet" style="font-family:Times, serif">)</span><span>. One last thing: with recursion, we also factor in </span><span>the</span><span> additional stack space as we recurse. We</span><span>’</span><span>ll briefly touch on that later. </span></p></div><div style="clear:both; mso-break-type:section-break; page-break-before:auto"><p class="Challenge" style="font-size:1.27em; line-height:115%"><span style="font-family:Times, serif; text-decoration:none"></span><span style="color:#000000; font-size:0.86em; text-decoration:none"> </span><span style="font-size:0.86em">Array: I</span><span style="font-size:0.86em">nsertion Sort</span></p><p class="Normal1"><span>Create a function that InsertionSort to sort </span><span>an unsorted</span><span> array in-place.</span><span> </span><span>What is the run-time complexity?</span><span> What is the space complexity</span><span>?</span></p><p class="Normal1"><span>&#xa0;</span></p><p class="Challenge" style="font-size:1.27em; line-height:115%"><span style="font-family:Times, serif; text-decoration:none"></span><span style="color:#000000; font-size:0.86em; text-decoration:none"> </span><span style="font-size:0.86em">Array: Combine</span></p><p class="Normal1" style="line-height:115%"><span>Create function </span><span class="CodeSnippet" style="font-family:Times, serif">combineArrs(arr1,arr2)</span><span> that sorts two already separately sorted arrays, placing the result back into the first provided array</span><span>. </span><span>Can you work completely in-place?</span><span> </span></p><p class="Challenge" style="font-size:1.27em; line-height:115%"><br style="mso-column-break-before:always; clear:both" /><span style="font-family:Times, serif; text-decoration:none"></span><span style="color:#000000; font-size:0.86em; text-decoration:none"> </span><span style="font-size:0.86em">SL</span><span style="font-size:0.86em">ist: I</span><span style="font-size:0.86em">nsertion Sort</span></p><p class="Normal1" style="line-height:115%"><span>Use</span><span> InsertionSort to sort singly linked lists. </span><span>Only reference </span><span class="CodeSnippet" style="font-family:Times, serif">ListNode</span><span> attributes </span><span class="CodeSnippet" style="font-family:Times, serif">.val</span><span> and </span><span class="CodeSnippet" style="font-family:Times, serif">.next</span><span>. What are </span><span>the </span><span>run-time and space complexities?</span></p><p class="Challenge" style="font-size:1.27em; line-height:115%"><span style="font-family:Times, serif; text-decoration:none"></span><span style="color:#000000; font-size:0.86em; text-decoration:none"> </span><span style="font-size:0.86em">SList: Combine</span></p><p style="line-height:115%"><span>Create a function that combines two already-sorted linked lists, returning a sorted list with both inputs. List nodes contain </span><span class="CodeSnippet" style="font-family:Times, serif">.val</span><span>,</span><span> </span><span class="CodeSnippet" style="font-family:Times, serif">.next</span><span> and</span><span> other attributes that you should not reference.</span></p></div><div style="clear:both; mso-break-type:section-break; page-break-before:auto"><p><br style="page-break-before:always; clear:both" /></p><p class="PageHeader"><span>Chapter 12</span><span> – Sorts </span></p><p class="Normal1" style="border-top-color:#000000; border-top-style:solid; border-top-width:0.5pt; padding-top:1pt"><span>&#xa0;</span></p><p class="Normal1" style="line-height:115%; margin-bottom:0pt; margin-top:0pt"><span>When discussing sorting algorithms, we talk</span><span> mostly about </span><span style="font-style:italic">run-time </span><span>performance </span><span>–</span><span> </span><span style="font-style:italic">how does Time N</span><span style="font-style:italic">eeded </span><span style="font-style:italic">change, as input </span><span style="font-style:italic">size grows?</span><span> </span><span>But </span><span>Big-O can also refer to resource consum</span><span>ption:</span><span> memory, storage or network bandwidth</span><span> – most commonly, </span><span>RAM.</span><span> The memory consumed by </span><span>an algorithm </span><span>is either </span><span>heap or call</span><span> </span><span>stack or both.</span><span> </span><span>These correspond to 1) </span><span>copying</span><span> </span><span>an</span><span> input or 2) making recursive calls.</span><span> </span><span>Clearly, all things equal, an algorithm </span><span>shouldn’t</span><span> make a copy of the input.</span><span> </span><span>After all, </span><span>we might receive</span><span> an array containing 4 billion values</span><span>! </span><span>Also, call-stacks are </span><span>not un</span><span>limited</span><span>;</span><span> it doesn</span><span>’</span><span>t take much to </span><span>“</span><span>blow our stack</span><span>”</span><span>.</span><span> E</span><span>verything </span><span>solved wi</span><span>th recursion </span><span>is solvable</span><span> without. More on </span><span class="CodeSnippet" style="font-family:Times, serif">O(space)</span><span> later</span><span>.</span></p><p class="Normal1" style="margin-bottom:0pt; margin-top:0pt"><span>&#xa0;</span></p><p class="Normal1" style="margin-top:0pt"><span>So,</span><span> which sorting algorithm is </span><span style="font-style:italic">truly</span><span> best?</span><span>&#xa0;</span><span>Again,</span><span> </span><span>the only</span><span> correct answer</span><span> is “depends on situation.” </span><span>However, there are numerous </span><span>characteristics that describe sorting algorithms, and we will discuss one each day through the rest of the </span><span>chapter</span><span>.</span><span> </span><span>Today we discuss what makes an algorithm </span><span style="font-style:italic; text-decoration:underline">Adaptive</span><span>.</span><span> </span></p></div></body></html>